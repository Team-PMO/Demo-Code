# Install Generative AI SDK.
!pip install -q -U google-generativeai

# Import libraries
from google.colab import files, userdata
import google.generativeai as genai
import re
from PIL import Image
import cv2
import numpy as np
from IPython.display import display

# Upload the reference and test images
print("Upload the REFERENCE (perfect) image:")
ref_upload = files.upload()
reference_image_name = list(ref_upload.keys())[0]
print(f"Uploaded reference image: {reference_image_name}")

print("Upload the TEST (inspection) image:")
test_upload = files.upload()
test_image_name = list(test_upload.keys())[0]
print(f"Uploaded test image: {test_image_name}")

# Set up API
API_KEY = userdata.get('NikKey')
genai.configure(api_key=API_KEY)

# Load Gemini model
model = genai.GenerativeModel(model_name='gemini-1.5-pro')

# Load the images
reference_img = Image.open(reference_image_name)
test_img = Image.open(test_image_name)

# Send both images to Gemini for comparison
response = model.generate_content([
    reference_img,
    test_img,
    (
        "Compare these two images of a product. "
        "The first image is the perfect reference, and the second is the test item. "
        "Identify only real imperfections or differences, such as loose threads, tears, rips, stains, holes, fabric fraying, "
        "color inconsistencies, missing parts, or other noticeable damage. "
        "If the two images are identical or no defects are found, explicitly respond with 'NO DEFECTS FOUND'. "
        "If defects are found, return the results as a list in this format: "
        "[ymin, xmin, ymax, xmax, defect_type]. "
        "Return a separate list for each detected defect."
    ),
])

# Show raw Gemini response for debugging
result = response.text
print("Gemini raw output:\n", result)

# Parse bounding box output
def parse_bounding_box(response):
    bounding_boxes = re.findall(r'\[(\d+,\s*\d+,\s*\d+,\s*\d+,\s*[\w\s]+)\]', response)
    parsed_boxes = []
    for box in bounding_boxes:
        parts = box.split(',')
        numbers = list(map(int, parts[:-1]))
        label = parts[-1].strip()
        parsed_boxes.append((numbers, label))
    return parsed_boxes

bounding_box = parse_bounding_box(result)
print(f"Parsed bounding boxes: {bounding_box}")

label_colors = {}

# Draw bounding boxes on detected defects
def draw_bounding_boxes(image, bounding_boxes_with_labels):
    if image.mode != 'RGB':
        image = image.convert('RGB')

    image = np.array(image)

    for bounding_box, label in bounding_boxes_with_labels:
        width, height = image.shape[1], image.shape[0]
        ymin, xmin, ymax, xmax = bounding_box
        x1 = int(xmin / 1000 * width)
        y1 = int(ymin / 1000 * height)
        x2 = int(xmax / 1000 * width)
        y2 = int(ymax / 1000 * height)

        if label not in label_colors:
            color = np.random.randint(0, 256, (3,)).tolist()
            label_colors[label] = color
        else:
            color = label_colors[label]

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        font_thickness = 1
        box_thickness = 2
        text_size = cv2.getTextSize(label, font, font_scale, font_thickness)[0]

        text_bg_x1 = x1
        text_bg_y1 = y1 - text_size[1] - 5
        text_bg_x2 = x1 + text_size[0] + 8
        text_bg_y2 = y1

        cv2.rectangle(image, (text_bg_x1, text_bg_y1), (text_bg_x2, text_bg_y2), color, -1)
        cv2.putText(image, label, (x1 + 2, y1 - 5), font, font_scale, (255, 255, 255), font_thickness)
        cv2.rectangle(image, (x1, y1), (x2, y2), color, box_thickness)

    image = Image.fromarray(image)
    return image

# Run and save output if defects are detected
if bounding_box:
    output = draw_bounding_boxes(test_img, bounding_box)
    display(output)
    output.save("output_image_with_defects.jpg")
    print("✅ Defect image saved as 'output_image_with_defects.jpg'")
else:
    print("✅ No visible defects detected.")
